{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -q -U nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RgeyssXN83N"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer, LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tag import pos_tag, pos_tag_sents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvZX3FeZO8nx",
        "outputId": "56a88395-a029-417b-c0bb-360ab5ce3637"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"tagsets\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "buMLbKT4PSwy"
      },
      "outputs": [],
      "source": [
        "text = '''Natural Language Processing (NLP) is a field of AI that uses \n",
        "Machine Learning (ML) to help computers understand and generate human \n",
        "language. By applying algorithms to data, NLP enables tasks like text analysis, translations, \n",
        "and question answering. ML improves these systems by allowing them to learn and adapt from examples.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB9hIba2QTlD",
        "outputId": "2bd724c1-88e9-42af-cafe-28609412ea83"
      },
      "outputs": [],
      "source": [
        "tokenized_sent = sent_tokenize(text, language=\"english\")\n",
        "print(type(tokenized_sent))\n",
        "print(tokenized_sent)\n",
        "print(len(tokenized_sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsrv-PtgQ-Ly",
        "outputId": "0ef6cb18-8e9f-489c-952d-a9e830c73b0f"
      },
      "outputs": [],
      "source": [
        "tokens = word_tokenize(text, language=\"english\")\n",
        "print(type(tokens))\n",
        "print(tokens)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9wENROXRKpm",
        "outputId": "ea0921a2-9deb-4897-e4c5-9c93fb6016da"
      },
      "outputs": [],
      "source": [
        "# Remove unnecessary words that might cause noise in results\n",
        "stops = stopwords.words(\"english\")\n",
        "print(stops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEvf_kZg7IRS",
        "outputId": "ce119cd3-0546-4846-da1b-229dcf0e9162"
      },
      "outputs": [],
      "source": [
        "# Remove from text the stop words\n",
        "tokens = [p for p in tokens if p not in stops]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYC_wZha8Qwl",
        "outputId": "0f447086-c23d-423b-fa4c-a04ad3642a32"
      },
      "outputs": [],
      "source": [
        "# Remove punctuation\n",
        "tokens_without_punct = [p for p in tokens if p not in string.punctuation]\n",
        "print(tokens_without_punct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqJdzuWr8z4l",
        "outputId": "ce4cce34-3155-41fb-ec4a-9d5170b8d744"
      },
      "outputs": [],
      "source": [
        "tokens_freq = nltk.FreqDist(tokens_without_punct)\n",
        "tokens_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTnILcJe9v7s",
        "outputId": "d90650aa-87a9-44e5-92ac-033884a3ce22"
      },
      "outputs": [],
      "source": [
        "# Most common\n",
        "most_common = tokens_freq.most_common(3)\n",
        "most_common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0uKVrpG9zbo",
        "outputId": "2ac16802-2ed3-4887-84a6-d699ff519983"
      },
      "outputs": [],
      "source": [
        "# Applying Stemmer by using Porter Stemmer method\n",
        "porter_stemmer = PorterStemmer()\n",
        "porter_stemmed  = [porter_stemmer.stem(word) for word in tokens_without_punct]\n",
        "print(tokens_without_punct)\n",
        "print(porter_stemmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdZC9wNh_BUG",
        "outputId": "a42e8f2f-84b5-491e-e39b-d558c81a62ec"
      },
      "outputs": [],
      "source": [
        "# Applying Stemmer by using Snowball Stemmer method\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "snowball_stemmed  = [snowball_stemmer.stem(word) for word in tokens_without_punct]\n",
        "print(tokens_without_punct)\n",
        "print(snowball_stemmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H-WTBaXAMCb",
        "outputId": "c35d10a4-630f-4d1b-af20-d7abb5d17ddc"
      },
      "outputs": [],
      "source": [
        "# Applying Stemmer by using Lancaster Stemmer method\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "lancaster_stemmed  = [lancaster_stemmer.stem(word) for word in tokens_without_punct]\n",
        "print(tokens_without_punct)\n",
        "print(lancaster_stemmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf3AdsjCAuiX",
        "outputId": "3063501c-08e5-465d-de23-53c82389f8fc"
      },
      "outputs": [],
      "source": [
        "# Print dictionary of tagset\n",
        "nltk.help.upenn_tagset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fit__7lFAzqL",
        "outputId": "1e635191-d807-4fcc-98d4-aa6ba5750eaf"
      },
      "outputs": [],
      "source": [
        "pos = nltk.pos_tag(tokens_without_punct)\n",
        "print(pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KalbBD2aBdFp",
        "outputId": "910ee66b-d9c9-4275-c153-8b10efb2e711"
      },
      "outputs": [],
      "source": [
        "# Lemmatize words (Sometimes better than Stemmer)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(tokens)\n",
        "print(lemmatized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwXYYIvxDBIB",
        "outputId": "673cd8cd-7ef9-4410-c6e4-d6e26076f46b"
      },
      "outputs": [],
      "source": [
        "# Named entities are the result of places, trademarks and names in the text is the result of places, trademarks and names in a text\n",
        "txt_en = \"Apple plans to open a new store in New York City next to Central Park by the end of October.\"\n",
        "en_token = word_tokenize(txt_en)\n",
        "tags = pos_tag(en_token)\n",
        "#aqui reconhece as entidades nomeadas\n",
        "en = nltk.ne_chunk(tags)\n",
        "print(en)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
